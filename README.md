# Data_Science_Projects

# [Project 1: Clean and Analyze "Employee Exit Survey"](https://github.com/linhChi2208/My-projects/tree/main/project1)
* In this project, I work with exit surveys from employees of the Department of Education, Training and Employment (DETE) and the Technical and Further Education (TAFE) institute in Queensland, Australia. Suppose that we are required to combine 2 datasets to answer the questions of the stakeholders.
* I mainly focused on the cleanning stage: 
- starting from diagnosing data, simplifying our columns name, making some field and value validation.
- Detecting missing value, also succeeding in recognizing some hidden NULL values, which were recorded as '-'. Applying different skills to tackle with this type of data (NaN).
- Writing a function to automatically return the `value_count()` of DataFrame.
- Categorize our data and customize the index following our desired order.
- Visualize exploratory data analysis
* After performing many data cleaning tasks, I extracted some meaningful insight from that tidy data.


# [Project 2: OPTIMISE PROFIT WITH DATA DRIVEN DECISIONS (SQL PROJECT)](https://github.com/linhChi2208/My-projects/tree/main/project2)
* I used Chinook database (containing 11 tables), provided as a SQLite database file called `chinook.db` to answer some business questions. Chinook database tries to simulate the sort of database that most businesses use in reality, it contains information about a fictional digital music shop - kind of like a mini-iTunes store.
* Using `WITH` and `VIEW` to make temporary and permanent views.
* Chaining `WITH` statements to construct complex queries, I managed to classify the type of invoice.
* Joining data from more than two tables
* Using `CASE` (if/then logic in SQL) to categorize and sort values.
* Aggregating data to define some bussiness metrics.
* Constracting subqueries in `FROM`, `WHERE` statements
* Visualize EDA based on the concept of optimizing data-ink ratio.
